# Apache-DA-Airflow 1.0 

 

## Desarrollador del proyecto 

- [Wilmar Murillo Carmona](https://github.com/murillowilmar1) 

# Objetivo

- Implementaci贸n de un flujo de ejecuci贸n en la que se ejecute un proceso ETL, utiliozando el conjunto de datos Sales.csv, la idea principal es que este conjunto de datos pase por todos los procesos necasarios para el despliegue y  visualizaci贸n de los datos 



# Herramientas del proyecto 
- Python 
- Apache Airflow 
- Postgresql 
- Aws S3 
- AWS Athena 
- 


# Descripci贸n del proyecto  

### Carpetas 
las carpetas estan en el orden en la que se debe ejecutar el proyecto paso a paso

- **Sales_Data** : carpeta que almacena la fuente de datos sales.csv, esta es un fuente de datos  secundaria, ya que se descargaron de la pagina Kaggle. 

- **Request_send_data** : Esta carpeta contiene los archivos.py que ejecutan el requerimiento de los datos y el envio hacia la base de datos en postgresql



## Contexto


## Requerimientos 

### Etapas 

- 


